{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_Transformer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1Dm0UabjJm3tWlApVvdPcrZl0ay_5OR3c","authorship_tag":"ABX9TyPflnV53BNBsAYH/CGxyMJf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8pCitN_t3LPI","colab_type":"text"},"source":["# 5. Transformerの構成"]},{"cell_type":"markdown","metadata":{"id":"3ZhIIYB-4QNF","colab_type":"text"},"source":["## 5.1. 準備"]},{"cell_type":"code","metadata":{"id":"tzYgIlG_2_yp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1596317208462,"user_tz":-540,"elapsed":172002,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}},"outputId":"bfdc875d-e58e-4f42-875f-49f0829d0aac"},"source":["import sys\n","sys.path.append(\"/content/drive/My Drive/Transformer\")\n","\n","from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n","\n","train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(max_length=256, batch_size=32)\n","print(TEXT.vocab.vectors.shape)\n","batch = next(iter(train_dl))\n","print(batch.Text)\n","print(batch.Label)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["  0%|          | 0/999994 [00:00<?, ?it/s]Skipping token b'999994' with 1-dimensional vector [b'300']; likely a header\n","100%|█████████▉| 999855/999994 [01:51<00:00, 9457.67it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([69959, 300])\n","(tensor([[   2,  105,   43,  ...,    1,    1,    1],\n","        [   2,   14,   87,  ...,    4,   93,    3],\n","        [   2,   12, 1926,  ...,    1,    1,    1],\n","        ...,\n","        [   2,   52,   50,  ...,    5,    5,    3],\n","        [   2,   19,  213,  ..., 1325,    4,    3],\n","        [   2,   14,  382,  ...,  106,   16,    3]]), tensor([131, 256, 167, 129, 147, 145, 237, 147, 256, 227, 208, 158, 186, 196,\n","        256, 236, 177, 221, 160, 215, 256, 159, 256, 219, 256, 256, 256, 129,\n","        256, 256, 256, 256]))\n","tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n","        1, 1, 0, 1, 0, 0, 1, 0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pa-VM1W_WXxQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596329864056,"user_tz":-540,"elapsed":910,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F \n","import math"],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPYc7RRf7_MY","colab_type":"text"},"source":["## 5.2. Embedder"]},{"cell_type":"code","metadata":{"id":"Dv2tDBBM8Bz-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596325124691,"user_tz":-540,"elapsed":1042,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["# 単語IDから単語ベクトルへの変換\n","class Embedder(nn.Module):\n","    def __init__(self, text_embedding_vectors):\n","        super(Embedder, self).__init__()\n","\n","        # 学習済みモデルを読込み更新されないようにする\n","        self.emb = nn.Embedding.from_pretrained(embeddings=text_embedding_vectors, freeze=True)\n","\n","    def forward(self, x):\n","        return self.emb(x)\n"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M7l8fv6zU2MY","colab_type":"text"},"source":["## 5.3. PositionEncoder"]},{"cell_type":"code","metadata":{"id":"xvhetqyfU48N","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596325126549,"user_tz":-540,"elapsed":892,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["# 単語の位置を表すベクトルを付与\n","class PositionEncoder(nn.Module):\n","    def __init__(self, d_model=300, max_seq_len=256):\n","        super(PositionEncoder, self).__init__()\n","\n","        self.d_model = d_model      # 単語ベクトルの次元数\n","        self.pe = torch.zeros(max_seq_len, d_model) # 位置情報ベクトル\n","\n","        for pos in range(max_seq_len):\n","            for i in range(0, d_model, 2):\n","                self.pe[pos, i    ] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\n","                self.pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * i) / d_model)))\n","        self.pe = self.pe.unsqueeze(0)  # バッチの次元を付与\n","        self.pe.requires_grad = False   # 勾配を計算させない\n","\n","    def forward(self, x):\n","        return (math.sqrt(self.d_model) * x) + self.pe\n"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dU9pClbgdl0E","colab_type":"text"},"source":["## 5.4. Transformer"]},{"cell_type":"markdown","metadata":{"id":"5gvNQiL7dnrL","colab_type":"text"},"source":["### 5.4.1. Attention"]},{"cell_type":"code","metadata":{"id":"NOpilflWgVla","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596330700264,"user_tz":-540,"elapsed":920,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["# SingleHeadAttention\n","class Attention(nn.Module):\n","    def __init__(self, d_model=300):\n","        super(Attention, self).__init__()\n","\n","        self.d_model = d_model\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","        self.out = nn.Linear(d_model, d_model)\n","\n","    def forward(self, x, mask):\n","        q = self.q_linear(x)\n","        k = self.k_linear(x)\n","        v = self.v_linear(x)\n","\n","        # Attentionを計算\n","        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_model)\n","        weights = weights.masked_fill(mask.unsqueeze(1) == 0, -1e9)  # <pad>の重みが0になるようにする\n","        normalized_weights = F.softmax(weights, dim=-1)\n","        h = torch.matmul(normalized_weights, v)\n","        return self.out(h), normalized_weights\n"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Je9YZ0yudqGC","colab_type":"text"},"source":["### 5.4.2. FeedForward"]},{"cell_type":"code","metadata":{"id":"bY2X7hqVKmAe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596338323977,"user_tz":-540,"elapsed":905,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model=300, d_hidden=1024, drop_ratio=0.1):\n","        super(FeedForward, self).__init__()\n","\n","        self.layers = nn.Sequential(\n","            nn.Linear(d_model, d_hidden),\n","            nn.ReLU(),\n","            nn.Dropout(drop_ratio),\n","            nn.Linear(d_hidden, d_model)\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n"],"execution_count":82,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JC0jqva4du-K","colab_type":"text"},"source":["### 5.4.3. TransformerBlock"]},{"cell_type":"code","metadata":{"id":"hLxOMItiM1fN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596339690326,"user_tz":-540,"elapsed":913,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["class TransformerBlock(nn.Module):\n","    def __init__(self, d_model=300, d_hidden=10204, drop_ratio=0.1):\n","        super(TransformerBlock, self).__init__()\n","\n","        # Attention\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.attn = Attention(d_model)\n","        self.dropout1 = nn.Dropout(drop_ratio)\n","\n","        # FeedForward\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.ff = FeedForward(d_model, d_hidden, drop_ratio)\n","        self.dropout2 = nn.Dropout(drop_ratio)\n","\n","    def forward(self, x, mask):\n","        # Attention\n","        h, normalized_weights = self.attn(self.norm1(x), mask)\n","        h = x + self.dropout1(h)\n","\n","        # FeedForward\n","        h = h + self.dropout2(self.ff(self.norm2(h)))\n","\n","        return h, normalized_weights\n"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fk4FX_j_d0za","colab_type":"text"},"source":["## 5.5. ClassificationHead"]},{"cell_type":"code","metadata":{"id":"B07UPs8oXPjH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596342758920,"user_tz":-540,"elapsed":879,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["class ClassificationHead(nn.Module):\n","    def __init__(self, d_model=300, d_out=2):\n","        super(ClassificationHead, self).__init__()\n","\n","        self.layer = nn.Linear(d_model, d_out)\n","        nn.init.normal_(self.layer.weight, std=0.02)\n","        nn.init.normal_(self.layer.bias, 0)\n","\n","    def forward(self, x):\n","        return F.softmax(self.layer(x[:, 0, :]), dim=1)   # 最初の単語(<cls>)のみ使用する\n"],"execution_count":109,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LryWLaYmd6NU","colab_type":"text"},"source":["## 5.6. TransformerClassification"]},{"cell_type":"code","metadata":{"id":"HYhEcEtEZDgv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596342507686,"user_tz":-540,"elapsed":1038,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}}},"source":["class TransformerClassification(nn.Module):\n","    def __init__(self, emb_vectors, d_model=300, max_seq_len=256, d_hidden=1024, d_out=2, drop_ratio=0.1):\n","        super(TransformerClassification, self).__init__()\n","\n","        self.emb = Embedder(emb_vectors)\n","        self.pe = PositionEncoder(d_model, max_seq_len)\n","        self.trm1 = TransformerBlock(d_model, d_hidden, drop_ratio)\n","        self.trm2 = TransformerBlock(d_model, d_hidden, drop_ratio)\n","        self.head = ClassificationHead(d_model, d_out)\n","\n","    def forward(self, x, mask):\n","        h = self.pe(self.emb(x))\n","        h, attn_w1 = self.trm1(h, mask)\n","        h, attn_w2 = self.trm2(h, mask)\n","        h = self.head(h)\n","        return h, attn_w1, attn_w2\n"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C2f-zIB69DzB","colab_type":"text"},"source":["### 動作確認"]},{"cell_type":"code","metadata":{"id":"9YiqpvoR9FXX","colab_type":"code","colab":{}},"source":["d_model = 300\n","max_seq_len = 256\n","d_hidden = 1024\n","drop_ratio = 0.1\n","d_out = 2\n","\n","emb_in = batch.Text[0]\n","input_mask = (emb_in != TEXT.vocab.stoi[\"<pad>\"])       # 文章でない箇所をマスクする\n","\n","emb = Embedder(TEXT.vocab.vectors)\n","emb_out = emb(emb_in)\n","\n","pe = PositionEncoder(d_model=d_model, max_seq_len=max_seq_len)\n","pe_out = pe(emb_out)\n","\n","attention = Attention(d_model=d_model)\n","attention_out, normalized_weights = attention(pe_out, input_mask)\n","\n","ff = FeedForward(d_model=d_model, d_hidden=d_hidden, drop_ratio=drop_ratio)\n","ff_out = ff(attention_out)\n","\n","trm = TransformerBlock(d_model, d_hidden, drop_ratio)\n","trm_out, normalized_weights = trm(pe_out, input_mask)\n","\n","head = ClassificationHead(d_model, d_out)\n","head_out = head(trm_out)\n","\n","print(\"入力テンソルサイズ: {}\".format(emb_in.shape))\n","print(\"出力テンソルサイズ(Embedder): {}\".format(emb_out.shape))\n","print(\"出力テンソルサイズ(PositionEncoder): {}\".format(pe_out.shape))\n","print(\"出力テンソルサイズ(Attention): {}\".format(attention_out.shape))\n","print(\"出力テンソルサイズ(FeedForward): {}\".format(ff_out.shape))\n","print(\"出力テンソルサイズ(TransformerBlock): {}\".format(trm_out.shape))\n","print(\"出力テンソルサイズ(ClassificationHead): {}\".format(head_out.shape))\n","print(\"アテンションサイズ: {}\".format(normalized_weights.shape))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dUpvfwObcOe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":612},"executionInfo":{"status":"ok","timestamp":1596342825194,"user_tz":-540,"elapsed":2547,"user":{"displayName":"水代つばめ","photoUrl":"","userId":"05712836990767418031"}},"outputId":"adc942dd-7234-4d9f-db09-7e566503cb52"},"source":["batch = next(iter(train_dl))\n","input_mask = (emb_in != TEXT.vocab.stoi[\"<pad>\"])\n","\n","net = TransformerClassification(TEXT.vocab.vectors, d_model, max_seq_len, d_hidden, d_out, drop_ratio)\n","out, attn_w1, attn_w2 = net(batch.Text[0], input_mask)\n","print(out.shape)\n","print(attn_w1.shape)\n","print(attn_w2.shape)\n","print(out)\n"],"execution_count":112,"outputs":[{"output_type":"stream","text":["torch.Size([32, 2])\n","torch.Size([32, 256, 256])\n","torch.Size([32, 256, 256])\n","tensor([[0.0184, 0.9816],\n","        [0.0190, 0.9810],\n","        [0.0186, 0.9814],\n","        [0.0173, 0.9827],\n","        [0.0188, 0.9812],\n","        [0.0183, 0.9817],\n","        [0.0203, 0.9797],\n","        [0.0186, 0.9814],\n","        [0.0204, 0.9796],\n","        [0.0169, 0.9831],\n","        [0.0184, 0.9816],\n","        [0.0191, 0.9809],\n","        [0.0224, 0.9776],\n","        [0.0153, 0.9847],\n","        [0.0202, 0.9798],\n","        [0.0181, 0.9819],\n","        [0.0179, 0.9821],\n","        [0.0199, 0.9801],\n","        [0.0168, 0.9832],\n","        [0.0190, 0.9810],\n","        [0.0205, 0.9795],\n","        [0.0182, 0.9818],\n","        [0.0201, 0.9799],\n","        [0.0175, 0.9825],\n","        [0.0181, 0.9819],\n","        [0.0187, 0.9813],\n","        [0.0183, 0.9817],\n","        [0.0174, 0.9826],\n","        [0.0177, 0.9823],\n","        [0.0181, 0.9819],\n","        [0.0147, 0.9853],\n","        [0.0198, 0.9802]], grad_fn=<SoftmaxBackward>)\n"],"name":"stdout"}]}]}